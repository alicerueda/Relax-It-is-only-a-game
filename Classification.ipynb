{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relax! This is only a game\n",
    "A person under stress can affect their performance. Our interest lays in stress release video games that can reduce the abnormally high stress level. \n",
    "\n",
    "This project uses ECG signals to determine the stress level of a person before and after playing the stress release video games. To demonstrate the algorithm, different stress and non-stress ECG signals were used as input to the algorithm. After feature extraction, the features were fed into different statistical machine learning algorithms. The algorithms tested include Navie Bayes, Decision Tree and Gradient Boost. Among these algorithm Gradient Boost provided the highest accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import set_printoptions\n",
    "\n",
    "# Preparing dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "\n",
    "# Models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Performance Measure\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import metrics\n",
    "import statistics\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Dataset\n",
    "Loading the feature csv file into arrays and normalized the features to range of [0,1]. There are 49 signals in total with 21 stress signals and 28 non-stress signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Mean HR      SDNN     RMSSD  NN50    PNN50       SD1       SD2     ApEn  \\\n",
      "0   84.760  0.053441  0.031241    21  0.20243  0.022112  0.072271  0.30596   \n",
      "1   73.411  0.072690  0.083187   124  0.14045  0.058863  0.084277  0.69844   \n",
      "2   76.055  0.160820  0.211560   148  0.25641  0.149790  0.171150  0.87521   \n",
      "3   74.226  0.084564  0.102010    87  0.24691  0.072218  0.095325  0.75760   \n",
      "4  123.880  0.088389  0.110670    60  0.16639  0.078318  0.097424  0.80389   \n",
      "\n",
      "   VLF(ms^2)  LF(ms^2)  HF(ms^2)  LF/HF ratio       TP  VLF_lomb(ms^2)  \\\n",
      "0     12.406    3.9326    12.433      0.31630   30.541          400.21   \n",
      "1    170.560   77.1350    48.860      1.57870  324.600         2078.80   \n",
      "2    171.860  140.6900   235.750      0.59677  558.590         2899.80   \n",
      "3    141.100   73.2180    66.160      1.10670  321.040         2123.20   \n",
      "4    272.550   80.8040   166.750      0.48459  578.670          911.47   \n",
      "\n",
      "   LF_lomb(ms^2)  HF_lomb(ms^2)  LF/HF_lomb ratio  TP_lomb  Stress  \n",
      "0         846.71         432.62           1.95720   1515.7     0.0  \n",
      "1        3032.60        2657.60           1.14110   6144.8     1.0  \n",
      "2        2687.80        1491.60           1.80190   5930.1     1.0  \n",
      "3        2339.70        2652.70           0.88201   5748.5     0.0  \n",
      "4        2738.50        4473.90           0.61211   8917.6     0.0  \n"
     ]
    }
   ],
   "source": [
    "# load the feature files into panda with X contains the features and Y contains the corresponding labels\n",
    "\n",
    "filename = '~binhn/Downloads/stress_analysis.csv'\n",
    "names = ['Mean HR','SDNN','RMSSD','NN50','PNN50','SD1','SD2','ApEn',\n",
    "         'VLF(ms^2)','LF(ms^2)','HF(ms^2)','LF/HF ratio','TP',\n",
    "         'VLF_lomb(ms^2)','LF_lomb(ms^2)','HF_lomb(ms^2)','LF/HF_lomb ratio','TP_lomb','Stress']\n",
    "#dataframe = pd.read_csv(filename, names =names)\n",
    "df = pd.read_csv(filename, names=names)\n",
    "print(df.head(5))\n",
    "\n",
    "array = df.values\n",
    "X = np.array(df.iloc[:,0:18])\n",
    "y = np.array(df.iloc[:,18])\n",
    "y=y.reshape(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.196e-01 1.906e-02 8.005e-03 3.125e-02 2.706e-01 8.005e-03 2.523e-02\n",
      "  2.214e-03 1.925e-05 5.443e-06 3.416e-05 6.674e-02 1.642e-05 1.961e-03\n",
      "  3.140e-03 3.528e-03 3.235e-01 3.756e-03]\n",
      " [7.900e-02 3.263e-02 3.440e-02 2.788e-01 8.984e-02 3.439e-02 3.352e-02\n",
      "  5.225e-01 2.691e-04 1.105e-04 1.348e-04 5.928e-01 1.771e-04 1.167e-02\n",
      "  1.245e-02 2.703e-02 1.629e-01 1.730e-02]\n",
      " [8.845e-02 9.475e-02 9.962e-02 3.365e-01 4.281e-01 9.967e-02 9.346e-02\n",
      "  7.569e-01 2.712e-04 2.017e-04 6.511e-04 1.836e-01 3.050e-04 1.641e-02\n",
      "  1.098e-02 1.472e-02 2.929e-01 1.667e-02]\n",
      " [8.191e-02 4.100e-02 4.396e-02 1.899e-01 4.004e-01 4.398e-02 4.114e-02\n",
      "  6.010e-01 2.226e-04 1.048e-04 1.826e-04 3.961e-01 1.752e-04 1.192e-02\n",
      "  9.496e-03 2.698e-02 1.120e-01 1.614e-02]\n",
      " [2.594e-01 4.369e-02 4.836e-02 1.250e-01 1.655e-01 4.836e-02 4.259e-02\n",
      "  6.623e-01 4.302e-04 1.157e-04 4.604e-04 1.369e-01 3.159e-04 4.917e-03\n",
      "  1.119e-02 4.622e-02 5.889e-02 2.541e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the features into [0,1]\n",
    "scaler = MinMaxScaler(feature_range = (0,1)) # scale the values to min 0, max 1\n",
    "rescaledX = np.array(scaler.fit_transform(X)) # fit the trainning feature X into scaler\n",
    "\n",
    "set_printoptions(precision=3) # how many decimal places.\n",
    "print(rescaledX[0:5,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification \n",
    "The classifiers tested in this project include Decision Tree, Each classifier uses 5-fold for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "# Decision Tree\n",
    "DT = DecisionTreeClassifier(random_state=0)\n",
    "# Gradient Boost\n",
    "GB = GradientBoostingClassifier(n_estimators=100, \n",
    "                                learning_rate=1.0, \n",
    "                                max_depth=1, \n",
    "                                random_state=0)\n",
    "\n",
    "# Support Vector Machine\n",
    "SVM = SVC(random_state = 0, gamma='scale',probability = True)\n",
    "\n",
    "# Linear Discrimant Analysis\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "GNB = GaussianNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificaiton function with K-Fold cross-validation with user define iterations to get the standard deviation \n",
    "\n",
    "def classify(model, Iterations, num_folds, rescaledX, y):\n",
    "    acc = []\n",
    "    pre = []\n",
    "    rec = []\n",
    "    rocauc = []\n",
    "    Skip = False\n",
    "\n",
    "    for i in range(Iterations):\n",
    "\n",
    "        # Shuffle the dataset for each iteration\n",
    "        data = list(zip(rescaledX,y))\n",
    "        random.shuffle(data)\n",
    "        rescaledX, y = zip(*data)\n",
    "        rescaledX = np.array(rescaledX)\n",
    "        y = np.array(y)\n",
    "        #y = y.reshape(-1,1)\n",
    "\n",
    "        # Perform 5-fold validation\n",
    "        kfold = KFold(n_splits = num_folds)#, shuffle=True, random_state = None)\n",
    "        #results = cross_val_score(DT, rescaledX, y, cv = kfold)\n",
    "        #print(results)\n",
    "\n",
    "        for train_index, test_index in kfold.split(rescaledX):\n",
    "            X_train, X_test = rescaledX[train_index], rescaledX[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            y_total = sum(y_test)\n",
    "            if (y_total == 0) or (y_total == len(y_test)):\n",
    "                Skip = True\n",
    "                \n",
    "            if not Skip:\n",
    "                # perform training and testing\n",
    "                if model == SVC:\n",
    "                    model.fit(X_train,y_train)\n",
    "                else:\n",
    "                    model.fit(X_train,y_train.ravel())\n",
    "                #dtscores = DT.score(X_test,y_test)\n",
    "                yPred = model.predict(X_test)\n",
    "\n",
    "\n",
    "                # record performance\n",
    "                acc = np.append(acc,metrics.accuracy_score(y_test, yPred)) \n",
    "                pre = np.append(pre,metrics.precision_score(y_test,\n",
    "                                                            yPred, \n",
    "                                                            pos_label=1, \n",
    "                                                            average='macro', \n",
    "                                                            labels=np.unique(yPred)))\n",
    "                rec = np.append(rec,metrics.recall_score(y_test,\n",
    "                                                         yPred, \n",
    "                                                         pos_label=1, \n",
    "                                                         average='macro', \n",
    "                                                         labels=np.unique(yPred)))\n",
    "                rocauc = np.append(rocauc, metrics.roc_auc_score(y_test, \n",
    "                                                                 yPred,\n",
    "                                                                 average='macro'))\n",
    "    return acc, pre, rec, rocauc\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter setting\n",
    "The classification are set to 100 iteration using 5-fold cross validation.\n",
    "\n",
    "NOTE: You might encounter single predicted labels instead of 2 class labels. This will return an error. The easiest work around is to run the cell again to shuffle tthe data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iterations = 100\n",
    "num_folds = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discrimant Analysis\n",
    "\n",
    "This section classifies the features using a Linear Discriminant Analysis (LDA) classifier.\n",
    "\n",
    "\n",
    "From the warning of collinear variables, a more meaning results maybe obtained by first using features selection techniques to remove dependent variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "Accuracy (mean, std): 0.6702020202020202 0.10104604939923673\n",
      "Precision (mean, std): 0.6784361471861472 0.13562548461005922\n",
      "Recall (mean, std): 0.6504599567099567 0.13562548461005922\n",
      "Area under the Receiver Operating Characteristic Curve 0.6504599567099567 0.12400042133484585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\Users\\binhn\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "print('Support Vector Machine')\n",
    "acc, pre, rec, rocauc = classify(LDA, Iterations, num_folds,  rescaledX, y)\n",
    "print('Accuracy (mean, std):', statistics.mean(acc), statistics.stdev(acc))\n",
    "print('Precision (mean, std):', statistics.mean(pre), statistics.stdev(pre))\n",
    "print('Recall (mean, std):', statistics.mean(rec), statistics.stdev(pre))\n",
    "print('Area under the Receiver Operating Characteristic Curve', statistics.mean(rocauc), statistics.stdev(rocauc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Accuracy (mean, std): 0.719164118246687 0.16612994208767567\n",
      "Precision (mean, std): 0.7263761467889909 0.17796915359502816\n",
      "Recall (mean, std): 0.7230176933158584 0.17796915359502816\n",
      "Area under the Receiver Operating Characteristic Curve 0.7184305373525557 0.17631877446410993\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree')\n",
    "acc, pre, rec, rocauc = classify(DT, Iterations, num_folds,  rescaledX, y)\n",
    "print('Accuracy (mean, std):', statistics.mean(acc), statistics.stdev(acc))\n",
    "print('Precision (mean, std):', statistics.mean(pre), statistics.stdev(pre))\n",
    "print('Recall (mean, std):', statistics.mean(rec), statistics.stdev(pre))\n",
    "print('Area under the Receiver Operating Characteristic Curve', statistics.mean(rocauc), statistics.stdev(rocauc))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine\n",
      "Accuracy (mean, std): 0.7591522157996147 0.11797441377783108\n",
      "Precision (mean, std): 0.8028012891090925 0.12347804484293638\n",
      "Recall (mean, std): 0.744481718506285 0.12347804484293638\n",
      "Area under the Receiver Operating Characteristic Curve 0.7372562849802734 0.12353236250486767\n"
     ]
    }
   ],
   "source": [
    "print('Support Vector Machine')\n",
    "acc, pre, rec, rocauc = classify(SVM, Iterations, num_folds,  rescaledX, y)\n",
    "print('Accuracy (mean, std):', statistics.mean(acc), statistics.stdev(acc))\n",
    "print('Precision (mean, std):', statistics.mean(pre), statistics.stdev(pre))\n",
    "print('Recall (mean, std):', statistics.mean(rec), statistics.stdev(pre))\n",
    "print('Area under the Receiver Operating Characteristic Curve', statistics.mean(rocauc), statistics.stdev(rocauc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "Accuracy (mean, std): 0.8496222222222223 0.14260464582027202\n",
      "Precision (mean, std): 0.8595706349206349 0.14118902637414696\n",
      "Recall (mean, std): 0.8500333333333333 0.14118902637414696\n",
      "Area under the Receiver Operating Characteristic Curve 0.8470333333333333 0.1442871082170833\n"
     ]
    }
   ],
   "source": [
    "print('Gradient Boosting')\n",
    "acc, pre, rec, rocauc = classify(GB, Iterations, num_folds,  rescaledX, y)\n",
    "print('Accuracy (mean, std):', statistics.mean(acc), statistics.stdev(acc))\n",
    "print('Precision (mean, std):', statistics.mean(pre), statistics.stdev(pre))\n",
    "print('Recall (mean, std):', statistics.mean(rec), statistics.stdev(pre))\n",
    "print('Area under the Receiver Operating Characteristic Curve', statistics.mean(rocauc), statistics.stdev(rocauc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes\n",
      "Accuracy (mean, std): 0.6433555555555556 0.14638336741099803\n",
      "Precision (mean, std): 0.6625242063492064 0.18695766868172312\n",
      "Recall (mean, std): 0.6815710317460317 0.18695766868172312\n",
      "Area under the Receiver Operating Characteristic Curve 0.5995710317460318 0.13875951327728075\n"
     ]
    }
   ],
   "source": [
    "print('Gaussian Naive Bayes')\n",
    "acc, pre, rec, rocauc = classify(GNB, Iterations, num_folds,  rescaledX, y)\n",
    "print('Accuracy (mean, std):', statistics.mean(acc), statistics.stdev(acc))\n",
    "print('Precision (mean, std):', statistics.mean(pre), statistics.stdev(pre))\n",
    "print('Recall (mean, std):', statistics.mean(rec), statistics.stdev(pre))\n",
    "print('Area under the Receiver Operating Characteristic Curve', statistics.mean(rocauc), statistics.stdev(rocauc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not tested Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ExtraTreesClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-020d70eb5ac1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Extra Trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m clf = ExtraTreesClassifier(n_estimators=10,\n\u001b[0m\u001b[0;32m      3\u001b[0m                            \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                            \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                            random_state=0)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ExtraTreesClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Extra Trees\n",
    "clf = ExtraTreesClassifier(n_estimators=10,\n",
    "                           max_depth=None,\n",
    "                           min_samples_split=2, \n",
    "                           random_state=0)\n",
    "# AdaBoost\n",
    "clf2 = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
